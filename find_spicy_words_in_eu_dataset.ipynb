{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import utils\n",
    "from collections import OrderedDict, Counter\n",
    "import ast\n",
    "import swifter\n",
    "from spicy_words import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eu = pd.read_csv(\"filtered_eu.csv\") # load data\n",
    "df_eu[\"name_list\"] = df_eu[\"name_list\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/financial.json\n",
      "spicy_words_segmented/personality.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m spicy_re \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mlist_to_regex(word_list)\n\u001b[1;32m     14\u001b[0m spicy_dict \u001b[39m=\u001b[39m {word: [] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m word_list}\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df_eu\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m     17\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m word_list:\n\u001b[1;32m     18\u001b[0m         segname \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/frame.py:1400\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m using_cow \u001b[39m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1399\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues):\n\u001b[0;32m-> 1400\u001b[0m     s \u001b[39m=\u001b[39m klass(v, index\u001b[39m=\u001b[39;49mcolumns, name\u001b[39m=\u001b[39;49mk)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1401\u001b[0m     \u001b[39mif\u001b[39;00m using_cow \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mis_single_block:\n\u001b[1;32m   1402\u001b[0m         s\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39madd_references(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/series.py:511\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m--> 511\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39;49m\u001b[39mmode.data_manager\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    512\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    513\u001b[0m         data \u001b[39m=\u001b[39m SingleBlockManager\u001b[39m.\u001b[39mfrom_array(data, index, refs\u001b[39m=\u001b[39mrefs)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/_config/config.py:261\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__func__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/_config/config.py:134\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    129\u001b[0m     key \u001b[39m=\u001b[39m _translate_key(key)\n\u001b[1;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m key\n\u001b[0;32m--> 134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_option\u001b[39m(pat: \u001b[39mstr\u001b[39m, silent: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    135\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(pat, silent)\n\u001b[1;32m    137\u001b[0m     \u001b[39m# walk the nested dict\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "names = [\n",
    "    'financial',\n",
    "    'personality',\n",
    "    'health',\n",
    "    'sex',\n",
    "    'latent_racism',\n",
    "    'religion',\n",
    "    'political'\n",
    "]\n",
    "\n",
    "for i, word_list in enumerate([financial, personality, health, sex, latent_racism, religion, political]):\n",
    "    spicy_re = utils.list_to_regex(word_list)\n",
    "\n",
    "    spicy_dict = {word: [] for word in word_list}\n",
    "\n",
    "    for index, row in df_eu.iterrows():\n",
    "        for word in word_list:\n",
    "            segname = row[\"name\"]\n",
    "            provider = row[\"provider_name\"]\n",
    "            if res := re.search(word.replace(\" \", utils.word_separator), segname):\n",
    "                spicy_dict[word].append(segname)\n",
    "\n",
    "    filename = f\"spicy_words_segmented/{names[i]}.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(spicy_dict, f, indent=4)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347783a20596409c9a07bb1a5e499e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/financial.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6dc8b22ef847b8bd35dd750f153e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/personality.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b125daad47034db4abd5fc906e8c9ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/health.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc867c2996e147cb8c7cba1ba97a8116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/sex.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae61cb6ee4f493bb6fd23f629723f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/latent_racism.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58784a9c5cc94d2a9338aaed70c38c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/religion.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f3f63dd25449039b30b48a2168367f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/political.csv\n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "    'financial',\n",
    "    'personality',\n",
    "    'health',\n",
    "    'sex',\n",
    "    'latent_racism',\n",
    "    'religion',\n",
    "    'political'\n",
    "]\n",
    "\n",
    "def find_spicy_words(row, word_list):\n",
    "    for word in word_list:\n",
    "        segname = row[\"name\"]\n",
    "        if res := re.search(word.replace(\" \", utils.word_separator), segname):\n",
    "            row[\"hit\"] = word\n",
    "            break\n",
    "    return row\n",
    "\n",
    "df_eu[\"hit\"] = None\n",
    "\n",
    "\n",
    "for i, word_list in enumerate([financial, personality, health, sex, latent_racism, religion, political]):\n",
    "    spicy_re = utils.list_to_regex(word_list)\n",
    "\n",
    "    spicy_dict = {word: [] for word in word_list}\n",
    "\n",
    "    df_hits = df_eu.swifter.apply(lambda x: find_spicy_words(x, word_list), axis=1)\n",
    "    df_hits = df_hits[df_hits.apply(lambda x: bool(x[\"hit\"]), axis=1)].reset_index(drop=True)\n",
    "\n",
    "    df_hits = df_hits.sort_values([\"hit\", \"name\"])\n",
    "\n",
    "    filename = f\"spicy_words_segmented/{names[i]}.csv\"\n",
    "    df_hits[[\"id\", \"hit\", \"name\", \"countries\"]].to_csv(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2302891a364b45468da12bc6e52c16be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/43870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spicy_words_segmented/late_comers.csv\n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "    'late_comers'\n",
    "]\n",
    "\n",
    "def find_spicy_words(row, word_list):\n",
    "    for word in word_list:\n",
    "        segname = row[\"name\"]\n",
    "        if res := re.search(word.replace(\" \", utils.word_separator), segname):\n",
    "            row[\"hit\"] = word\n",
    "            break\n",
    "    return row\n",
    "\n",
    "df_eu[\"hit\"] = None\n",
    "\n",
    "\n",
    "for i, word_list in enumerate([late_comers]):\n",
    "    spicy_re = utils.list_to_regex(word_list)\n",
    "\n",
    "    spicy_dict = {word: [] for word in word_list}\n",
    "\n",
    "    df_hits = df_eu.swifter.apply(lambda x: find_spicy_words(x, word_list), axis=1)\n",
    "    df_hits = df_hits[df_hits.apply(lambda x: bool(x[\"hit\"]), axis=1)].reset_index(drop=True)\n",
    "\n",
    "    df_hits = df_hits.sort_values([\"hit\", \"name\"])\n",
    "\n",
    "    filename = f\"spicy_words_segmented/{names[i]}.csv\"\n",
    "    df_hits[[\"id\", \"hit\", \"name\", \"countries\"]].to_csv(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

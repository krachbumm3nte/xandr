{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import utils\n",
    "from collections import OrderedDict, Counter\n",
    "import ast\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itemized = pd.read_json(\"xandr_segments_itemized.json\") # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_countries = pd.read_csv(\"eu_countries.csv\")\n",
    "\n",
    "eu_countries[\"names_re\"] = np.nan\n",
    "eu_countries[\"code_set\"] = np.nan\n",
    "\n",
    "eu_countries[\"codes\"] = eu_countries[\"codes\"].apply(ast.literal_eval)\n",
    "eu_countries[\"strings\"] = eu_countries[\"strings\"].apply(ast.literal_eval)\n",
    "eu_countries[\"identifiers\"] = eu_countries[\"identifiers\"].apply(ast.literal_eval)\n",
    "eu_names_re = \"|\".join(np.concatenate(eu_countries[[\"strings\", \"identifiers\"]].values.flatten()))\n",
    "eu_codes = set(np.concatenate(eu_countries[\"codes\"].values.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_count = Counter(np.concatenate(df_itemized[\"name_list\"].values))\n",
    "with open(\"tags.json\", \"w\") as f:\n",
    "    json.dump(OrderedDict(tag_count.most_common()), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7dce376fc64a88af0708d01af77a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/649110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel_word_list = [\"travel\", \"departure\", \"destination\",\n",
    "                    \"tourism\", \"tourist\", \"vacation\", \"holiday\", \"voyage\", \"expedia\"]\n",
    "\n",
    "eu_false_positives = [\"(furniture|nail) polish\",  # ethnicity FPs\n",
    "                      \"irish (whiskey|cream)\",\n",
    "                      \"speak(er|ing)\",\n",
    "                      \"language\",\n",
    "                      \"hispanic\",\n",
    "                      \"tour de france\",\n",
    "                      \"greek joghurt\",\n",
    "\n",
    "                      # Country code FPs\n",
    "                      \"accuen\",  # does market research and very little location-specifics. Thus many FPs\n",
    "                      \"xaxisus\",  # us source\n",
    "                      \"xaxisca\",  # canadian source\n",
    "                      \"xaxisapc\",  # whatever the fuck it is, it's not useful\n",
    "                      \"tailtarget\",  # mostly latAm focussed -> numerous es/pt FPs\n",
    "                      \"\\A\\d{20}\",\n",
    "                      ]\n",
    "\n",
    "\n",
    "false_positive_re = \"|\".join(travel_word_list + eu_false_positives)\n",
    "filtered_travel_words = df_itemized[df_itemized.swifter.apply(\n",
    "    lambda x: not re.search(false_positive_re, x[\"name\"]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1821d1612ad6411dbcaad8875f4329a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/622147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "us_re = \"united[ -â€“_]states|unitedstates|usa\"\n",
    "\n",
    "def filter_us_names(row):\n",
    "    # does the full country name occur anywhere or does a countrycode match an item exactly?\n",
    "    return bool(re.search(us_re, row[\"name\"]) or any([el == \"usa\" or el.startswith(\"us \") or el.endswith(\" us\") for el in row[\"name_list\"]]))\n",
    "\n",
    "filtered_us = filtered_travel_words[filtered_travel_words.swifter.apply(filter_us_names, axis=1)]\n",
    "filtered_us.to_csv(\"filtered_us.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458d3285082e49198c03d6a0da534a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/609420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_eu_names(row):\n",
    "    # does the full country name occur anywhere or does a countrycode match an item exactly?\n",
    "    return bool(re.search(eu_names_re, row[\"name\"]) or len(eu_codes.intersection(row[\"name_list\"])))\n",
    "\n",
    "def filter_eu_codes(row):\n",
    "    # does the full country name occur anywhere or does a countrycode match an item exactly?\n",
    "    return len(eu_codes.intersection(row[\"name_list\"])) > 0\n",
    "\n",
    "eu_ethnicities_re = \"|\".join([x[1] for x in eu_countries[\"strings\"].values])\n",
    "\n",
    "\n",
    "def filter_eu_ethnicities(row):\n",
    "    # does the full country name occur anywhere or does a countrycode match an item exactly?\n",
    "    return bool(re.search(eu_ethnicities_re, row[\"name\"]))\n",
    "\n",
    "\n",
    "filtered_eu = filtered_travel_words[filtered_travel_words.swifter.apply(filter_eu_names, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_eu.to_csv(\"filtered_eu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86dacdbbf704942b7f5e2a290c754ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/622147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf9585d76a441f8a7a75deb36518b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/622147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_travel_words[filtered_travel_words.swifter.apply(filter_eu_codes, axis=1)].to_csv(\"filtered_eu_codes.csv\")\n",
    "filtered_travel_words[filtered_travel_words.swifter.apply(filter_eu_ethnicities, axis=1)].to_csv(\"filtered_eu_ethnicities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered_eu_segnames.json\", \"w\") as f:\n",
    "    json.dump(list(filtered_eu[\"name\"].array), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_dict = {word:{} for word in spicy_words}\n",
    "for index, row in filtered_eu.iterrows():\n",
    "    segname = row[\"name\"]\n",
    "    provider = row[\"provider_name\"]\n",
    "    res = re.findall(spicy_word_re, segname)\n",
    "    if res:\n",
    "        res = set(res)\n",
    "        for tag in res:\n",
    "            if provider in spicy_dict[tag]:\n",
    "                spicy_dict[tag][provider].append(segname)\n",
    "            else:\n",
    "                spicy_dict[tag][provider] = [segname]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k,v in spicy_dict.items():\n",
    "    for k2, v2 in v.items():\n",
    "        v[k2] = sorted(v2)\n",
    "\n",
    "\n",
    "with open(\"spicy_words_eu.json\", \"w\") as f:\n",
    "    json.dump(spicy_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spicy_dict_global = {word:{} for word in spicy_words}\n",
    "for index, row in df_itemized.iterrows():\n",
    "    segname = row[\"name\"]\n",
    "    provider = row[\"provider_name\"]\n",
    "    res = re.findall(spicy_word_re, segname)\n",
    "    if res:\n",
    "        res = set(res)\n",
    "        for tag in res:\n",
    "            if provider in spicy_dict_global[tag]:\n",
    "                spicy_dict_global[tag][provider].append(segname)\n",
    "            else:\n",
    "                spicy_dict_global[tag][provider] = [segname]\n",
    "\n",
    "\n",
    "for k,v in spicy_dict_global.items():\n",
    "    for k2, v2 in v.items():\n",
    "        v[k2] = sorted(v2)\n",
    "    # spicy_dict[k] = sorted(v)\n",
    "\n",
    "\n",
    "with open(\"spicy_words_global.json\", \"w\") as f:\n",
    "    json.dump(spicy_dict_global, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = eu_countries[\"name\"].values\n",
    "strings = eu_countries[\"strings\"].values\n",
    "codes = eu_countries[\"codes\"].values\n",
    "identifiers = eu_countries[\"identifiers\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_counter = {country: [] for country in countries}\n",
    "\n",
    "country_re = [\"|\".join(strings[i]+identifiers[i]) for i in range(len(strings))]\n",
    "\n",
    "for index, row in filtered_travel_words.iterrows():\n",
    "    for i, country in enumerate(countries):\n",
    "        segname = row[\"name\"]\n",
    "        \n",
    "        if re.search(country_re[i], segname) or codes[i] in row[\"name_list\"]:\n",
    "            eu_counter[country].append(segname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "germany 4849\n",
      "spain 3528\n",
      "france 3371\n",
      "italy 2288\n",
      "denmark 1953\n",
      "sweden 1398\n",
      "europe 1037\n",
      "poland 544\n",
      "finland 507\n",
      "austria 477\n",
      "belgium 455\n",
      "romania 406\n",
      "netherlands 374\n",
      "hungary 268\n",
      "portugal 211\n",
      "greece 155\n",
      "ireland 117\n",
      "czechia 98\n",
      "croatia 28\n",
      "malta 25\n",
      "bulgaria 18\n",
      "slovakia 18\n",
      "estonia 15\n",
      "cyprus 15\n",
      "slovenia 14\n",
      "lithuania 13\n",
      "latvia 12\n",
      "luxembourg 11\n"
     ]
    }
   ],
   "source": [
    "counts = OrderedDict([(k, len(v)) for k,v in eu_counter.items()])\n",
    "for a, b in sorted(counts.items(), key= lambda x: x[1], reverse=True):\n",
    "    print(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in counts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

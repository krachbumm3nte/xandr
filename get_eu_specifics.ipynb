{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import utils\n",
    "from collections import OrderedDict, Counter\n",
    "import ast\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itemized = pd.read_json(\"xandr_segments_itemized.json\") # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9487f4d6764836b07223ea4f7c1e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>strings</th>\n",
       "      <th>codes</th>\n",
       "      <th>identifiers</th>\n",
       "      <th>codes_set</th>\n",
       "      <th>names_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>belgium</td>\n",
       "      <td>[belgium, belgian, belgie]</td>\n",
       "      <td>[be, bel]</td>\n",
       "      <td>[xaxisbe, xaxisbel]</td>\n",
       "      <td>{bel, be}</td>\n",
       "      <td>re.compile('belgium|belgian|belgie|xaxisbe|xax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bulgaria</td>\n",
       "      <td>[bulgaria, bulgarian, bulgarija]</td>\n",
       "      <td>[bg, bgr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{bg, bgr}</td>\n",
       "      <td>re.compile('bulgaria|bulgarian|bulgarija')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>czechia</td>\n",
       "      <td>[czechia, czech, cesko, ceska]</td>\n",
       "      <td>[cz, cze]</td>\n",
       "      <td>[xaxiscz]</td>\n",
       "      <td>{cz, cze}</td>\n",
       "      <td>re.compile('czechia|czech|cesko|ceska|xaxiscz')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>denmark</td>\n",
       "      <td>[denmark, danish, danmark]</td>\n",
       "      <td>[dk, dnk]</td>\n",
       "      <td>[xaxisdk, dk ndr]</td>\n",
       "      <td>{dnk, dk}</td>\n",
       "      <td>re.compile('denmark|danish|danmark|xaxisdk|dk[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>germany</td>\n",
       "      <td>[germany, german, deutschland]</td>\n",
       "      <td>[de, deu, ger]</td>\n",
       "      <td>[xaxisde, de experian, de kantar]</td>\n",
       "      <td>{de, ger, deu}</td>\n",
       "      <td>re.compile('germany|german|deutschland|xaxisde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>estonia</td>\n",
       "      <td>[estonia, estonian, eesti]</td>\n",
       "      <td>[ee, est]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{ee, est}</td>\n",
       "      <td>re.compile('estonia|estonian|eesti')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ireland</td>\n",
       "      <td>[ireland, irish]</td>\n",
       "      <td>[ie, irl]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{irl, ie}</td>\n",
       "      <td>re.compile('ireland|irish')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>greece</td>\n",
       "      <td>[greece, greek]</td>\n",
       "      <td>[el, grc]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{grc, el}</td>\n",
       "      <td>re.compile('greece|greek')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>spain</td>\n",
       "      <td>[spain, spanish]</td>\n",
       "      <td>[es, esp]</td>\n",
       "      <td>[xaxises, es experian, experian sp]</td>\n",
       "      <td>{es, esp}</td>\n",
       "      <td>re.compile('spain|spanish|xaxises|es[\\\\ \\\\-–_\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>france</td>\n",
       "      <td>[france, french, francaise]</td>\n",
       "      <td>[fr, fra]</td>\n",
       "      <td>[xaxisfr, fr experian, experian fr, fr kantar]</td>\n",
       "      <td>{fra, fr}</td>\n",
       "      <td>re.compile('france|french|francaise|xaxisfr|fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>croatia</td>\n",
       "      <td>[croatia, croatian]</td>\n",
       "      <td>[hr, hrv]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{hrv, hr}</td>\n",
       "      <td>re.compile('croatia|croatian')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>italy</td>\n",
       "      <td>[italy, italian]</td>\n",
       "      <td>[it, ita]</td>\n",
       "      <td>[xaxisit, experian it]</td>\n",
       "      <td>{it, ita}</td>\n",
       "      <td>re.compile('italy|italian|xaxisit|experian[\\\\ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>cyprus</td>\n",
       "      <td>[cyprus, cypriot]</td>\n",
       "      <td>[cy, cyp]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{cyp, cy}</td>\n",
       "      <td>re.compile('cyprus|cypriot')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>latvia</td>\n",
       "      <td>[latvia, latvian]</td>\n",
       "      <td>[lv, lva]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{lv, lva}</td>\n",
       "      <td>re.compile('latvia|latvian')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>lithuania</td>\n",
       "      <td>[lithuania, lithuanian]</td>\n",
       "      <td>[lt, ltu]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{ltu, lt}</td>\n",
       "      <td>re.compile('lithuania|lithuanian')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>luxembourg</td>\n",
       "      <td>[luxembourg, luxembourgian]</td>\n",
       "      <td>[lu, lux]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{lu, lux}</td>\n",
       "      <td>re.compile('luxembourg|luxembourgian')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>hungary</td>\n",
       "      <td>[hungary, hungarian]</td>\n",
       "      <td>[hu, hun]</td>\n",
       "      <td>[xaxishu, xaxishungar]</td>\n",
       "      <td>{hu, hun}</td>\n",
       "      <td>re.compile('hungary|hungarian|xaxishu|xaxishun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>malta</td>\n",
       "      <td>[malta, maltese]</td>\n",
       "      <td>[mt, mlt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{mt, mlt}</td>\n",
       "      <td>re.compile('malta|maltese')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>netherlands</td>\n",
       "      <td>[netherland, dutch]</td>\n",
       "      <td>[nl, nld]</td>\n",
       "      <td>[xaxisnl, nl experian]</td>\n",
       "      <td>{nl, nld}</td>\n",
       "      <td>re.compile('netherland|dutch|xaxisnl|nl[\\\\ \\\\-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>austria</td>\n",
       "      <td>[austria, austrian, osterreich]</td>\n",
       "      <td>[at, aut]</td>\n",
       "      <td>[xaxaustria]</td>\n",
       "      <td>{at, aut}</td>\n",
       "      <td>re.compile('austria|austrian|osterreich|xaxaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>poland</td>\n",
       "      <td>[poland, polish]</td>\n",
       "      <td>[pl, pol]</td>\n",
       "      <td>[xaxispo]</td>\n",
       "      <td>{pol, pl}</td>\n",
       "      <td>re.compile('poland|polish|xaxispo')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>portugal</td>\n",
       "      <td>[portugal, portuguese]</td>\n",
       "      <td>[pt, prt]</td>\n",
       "      <td>[xaxispt]</td>\n",
       "      <td>{prt, pt}</td>\n",
       "      <td>re.compile('portugal|portuguese|xaxispt')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>romania</td>\n",
       "      <td>[romania, romanian]</td>\n",
       "      <td>[ro, rou]</td>\n",
       "      <td>[xaxisro]</td>\n",
       "      <td>{ro, rou}</td>\n",
       "      <td>re.compile('romania|romanian|xaxisro')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>slovenia</td>\n",
       "      <td>[slovenia, slovenian]</td>\n",
       "      <td>[si, svn]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{svn, si}</td>\n",
       "      <td>re.compile('slovenia|slovenian')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>slovakia</td>\n",
       "      <td>[slovakia, slovak]</td>\n",
       "      <td>[sk, svk]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{svk, sk}</td>\n",
       "      <td>re.compile('slovakia|slovak')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>finland</td>\n",
       "      <td>[finland, finnish]</td>\n",
       "      <td>[fi, fin]</td>\n",
       "      <td>[xaxisfi, fi ndr]</td>\n",
       "      <td>{fi, fin}</td>\n",
       "      <td>re.compile('finland|finnish|xaxisfi|fi[\\\\ \\\\-–...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>sweden</td>\n",
       "      <td>[sweden, swedish]</td>\n",
       "      <td>[se, swe]</td>\n",
       "      <td>[xaxisse, xaxissweden, se ndr]</td>\n",
       "      <td>{se, swe}</td>\n",
       "      <td>re.compile('sweden|swedish|xaxisse|xaxissweden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>europe</td>\n",
       "      <td>[europe, european]</td>\n",
       "      <td>[eu, eue]</td>\n",
       "      <td>[xaxisema]</td>\n",
       "      <td>{eu, eue}</td>\n",
       "      <td>re.compile('europe|european|xaxisema')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         name                           strings           codes  \\\n",
       "0            0      belgium        [belgium, belgian, belgie]       [be, bel]   \n",
       "1            1     bulgaria  [bulgaria, bulgarian, bulgarija]       [bg, bgr]   \n",
       "2            2      czechia    [czechia, czech, cesko, ceska]       [cz, cze]   \n",
       "3            3      denmark        [denmark, danish, danmark]       [dk, dnk]   \n",
       "4            4      germany    [germany, german, deutschland]  [de, deu, ger]   \n",
       "5            5      estonia        [estonia, estonian, eesti]       [ee, est]   \n",
       "6            6      ireland                  [ireland, irish]       [ie, irl]   \n",
       "7            7       greece                   [greece, greek]       [el, grc]   \n",
       "8            8        spain                  [spain, spanish]       [es, esp]   \n",
       "9            9       france       [france, french, francaise]       [fr, fra]   \n",
       "10          10      croatia               [croatia, croatian]       [hr, hrv]   \n",
       "11          11        italy                  [italy, italian]       [it, ita]   \n",
       "12          12       cyprus                 [cyprus, cypriot]       [cy, cyp]   \n",
       "13          13       latvia                 [latvia, latvian]       [lv, lva]   \n",
       "14          14    lithuania           [lithuania, lithuanian]       [lt, ltu]   \n",
       "15          15   luxembourg       [luxembourg, luxembourgian]       [lu, lux]   \n",
       "16          16      hungary              [hungary, hungarian]       [hu, hun]   \n",
       "17          17        malta                  [malta, maltese]       [mt, mlt]   \n",
       "18          18  netherlands               [netherland, dutch]       [nl, nld]   \n",
       "19          19      austria   [austria, austrian, osterreich]       [at, aut]   \n",
       "20          20       poland                  [poland, polish]       [pl, pol]   \n",
       "21          21     portugal            [portugal, portuguese]       [pt, prt]   \n",
       "22          22      romania               [romania, romanian]       [ro, rou]   \n",
       "23          23     slovenia             [slovenia, slovenian]       [si, svn]   \n",
       "24          24     slovakia                [slovakia, slovak]       [sk, svk]   \n",
       "25          25      finland                [finland, finnish]       [fi, fin]   \n",
       "26          26       sweden                 [sweden, swedish]       [se, swe]   \n",
       "27          27       europe                [europe, european]       [eu, eue]   \n",
       "\n",
       "                                       identifiers       codes_set  \\\n",
       "0                              [xaxisbe, xaxisbel]       {bel, be}   \n",
       "1                                               []       {bg, bgr}   \n",
       "2                                        [xaxiscz]       {cz, cze}   \n",
       "3                                [xaxisdk, dk ndr]       {dnk, dk}   \n",
       "4                [xaxisde, de experian, de kantar]  {de, ger, deu}   \n",
       "5                                               []       {ee, est}   \n",
       "6                                               []       {irl, ie}   \n",
       "7                                               []       {grc, el}   \n",
       "8              [xaxises, es experian, experian sp]       {es, esp}   \n",
       "9   [xaxisfr, fr experian, experian fr, fr kantar]       {fra, fr}   \n",
       "10                                              []       {hrv, hr}   \n",
       "11                          [xaxisit, experian it]       {it, ita}   \n",
       "12                                              []       {cyp, cy}   \n",
       "13                                              []       {lv, lva}   \n",
       "14                                              []       {ltu, lt}   \n",
       "15                                              []       {lu, lux}   \n",
       "16                          [xaxishu, xaxishungar]       {hu, hun}   \n",
       "17                                              []       {mt, mlt}   \n",
       "18                          [xaxisnl, nl experian]       {nl, nld}   \n",
       "19                                    [xaxaustria]       {at, aut}   \n",
       "20                                       [xaxispo]       {pol, pl}   \n",
       "21                                       [xaxispt]       {prt, pt}   \n",
       "22                                       [xaxisro]       {ro, rou}   \n",
       "23                                              []       {svn, si}   \n",
       "24                                              []       {svk, sk}   \n",
       "25                               [xaxisfi, fi ndr]       {fi, fin}   \n",
       "26                  [xaxisse, xaxissweden, se ndr]       {se, swe}   \n",
       "27                                      [xaxisema]       {eu, eue}   \n",
       "\n",
       "                                             names_re  \n",
       "0   re.compile('belgium|belgian|belgie|xaxisbe|xax...  \n",
       "1          re.compile('bulgaria|bulgarian|bulgarija')  \n",
       "2     re.compile('czechia|czech|cesko|ceska|xaxiscz')  \n",
       "3   re.compile('denmark|danish|danmark|xaxisdk|dk[...  \n",
       "4   re.compile('germany|german|deutschland|xaxisde...  \n",
       "5                re.compile('estonia|estonian|eesti')  \n",
       "6                         re.compile('ireland|irish')  \n",
       "7                          re.compile('greece|greek')  \n",
       "8   re.compile('spain|spanish|xaxises|es[\\\\ \\\\-–_\\...  \n",
       "9   re.compile('france|french|francaise|xaxisfr|fr...  \n",
       "10                     re.compile('croatia|croatian')  \n",
       "11  re.compile('italy|italian|xaxisit|experian[\\\\ ...  \n",
       "12                       re.compile('cyprus|cypriot')  \n",
       "13                       re.compile('latvia|latvian')  \n",
       "14                 re.compile('lithuania|lithuanian')  \n",
       "15             re.compile('luxembourg|luxembourgian')  \n",
       "16  re.compile('hungary|hungarian|xaxishu|xaxishun...  \n",
       "17                        re.compile('malta|maltese')  \n",
       "18  re.compile('netherland|dutch|xaxisnl|nl[\\\\ \\\\-...  \n",
       "19  re.compile('austria|austrian|osterreich|xaxaus...  \n",
       "20                re.compile('poland|polish|xaxispo')  \n",
       "21          re.compile('portugal|portuguese|xaxispt')  \n",
       "22             re.compile('romania|romanian|xaxisro')  \n",
       "23                   re.compile('slovenia|slovenian')  \n",
       "24                      re.compile('slovakia|slovak')  \n",
       "25  re.compile('finland|finnish|xaxisfi|fi[\\\\ \\\\-–...  \n",
       "26  re.compile('sweden|swedish|xaxisse|xaxissweden...  \n",
       "27             re.compile('europe|european|xaxisema')  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_countries = pd.read_csv(\"eu_countries.csv\")\n",
    "\n",
    "\n",
    "eu_countries[\"codes\"] = eu_countries[\"codes\"].apply(ast.literal_eval)\n",
    "eu_countries[\"codes_set\"] = eu_countries[\"codes\"].apply(lambda x: set(x))\n",
    "eu_countries[\"strings\"] = eu_countries[\"strings\"].apply(ast.literal_eval)\n",
    "eu_countries[\"identifiers\"] = eu_countries[\"identifiers\"].apply(ast.literal_eval)\n",
    "eu_countries[\"names_re\"] = eu_countries.swifter.apply(lambda row: utils.list_to_regex(np.concatenate(row[[\"strings\", \"identifiers\"]].values.flatten())), axis=1)\n",
    "\n",
    "eu_names_re = utils.list_to_regex(np.concatenate(eu_countries[[\"strings\", \"identifiers\"]].values.flatten()))\n",
    "eu_codes = set(np.concatenate(eu_countries[\"codes\"].values.flatten()))\n",
    "eu_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_count = Counter(np.concatenate(df_itemized[\"name_list\"].values))\n",
    "with open(\"tags.json\", \"w\") as f:\n",
    "    json.dump(OrderedDict(tag_count.most_common()), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a01ffa1fee43a3a405a451cac854e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/648930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "travel_word_list = [\"travel\", \"departure\", \"destination\",\n",
    "                    \"tourism\", \"tourist\", \"vacation\", \"holiday\", \"voyage\", \"expedia\"]\n",
    "\n",
    "eu_false_positives = [\"(furniture|nail) polish\",  # ethnicity FPs\n",
    "                      \"irish (whiskey|cream)\",\n",
    "                      \"speak(er|ing)\",\n",
    "                      # \"language\",\n",
    "                      # \"hispanic\",\n",
    "                      \"tour de france\",\n",
    "                      \"greek joghurt\",\n",
    "\n",
    "                      # Country code FPs\n",
    "                      \"accuen\",  # does market research and very little location-specifics. Thus many FPs\n",
    "                      \"xaxisus\",  # us source\n",
    "                      \"xaxisca\",  # canadian source\n",
    "                      \"xaxisapc\",  # whatever the fuck it is, it's not useful\n",
    "                      \"tailtarget\",  # mostly latAm focussed -> numerous es/pt FPs\n",
    "                      ]\n",
    "\n",
    "\n",
    "false_positive_re = utils.list_to_regex(travel_word_list + eu_false_positives)\n",
    "filtered_travel_words = df_itemized[df_itemized.swifter.apply(\n",
    "    lambda x: not re.search(false_positive_re, x[\"name\"]), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55decb29de274859868f69377a2253dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/613906 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/swifter/swifter.py:418\u001b[0m, in \u001b[0;36mDataFrameAccessor.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[0;32m--> 418\u001b[0m     tmp_df \u001b[39m=\u001b[39m func(sample, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    419\u001b[0m     sample_df \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mapply(func, axis\u001b[39m=\u001b[39maxis, raw\u001b[39m=\u001b[39mraw, result_type\u001b[39m=\u001b[39mresult_type, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m, in \u001b[0;36midentify_eu_names\u001b[0;34m(row_dataset)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i, names_re \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(names_re_list):\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39;49msearch(names_re, name) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(codes_set_list[i]\u001b[39m.\u001b[39mintersection(row_dataset[\u001b[39m\"\u001b[39m\u001b[39mname_list\u001b[39m\u001b[39m\"\u001b[39m])):\n\u001b[1;32m     16\u001b[0m         country_hits\u001b[39m.\u001b[39mappend(country_names[i])\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:200\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39ma Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\u001b[39m.\u001b[39;49msearch(string)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     row_dataset[\u001b[39m\"\u001b[39m\u001b[39mcountries\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m country_hits\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m row_dataset\n\u001b[0;32m---> 22\u001b[0m filtered_travel_words \u001b[39m=\u001b[39m filtered_travel_words\u001b[39m.\u001b[39;49mswifter\u001b[39m.\u001b[39;49mapply(identify_eu_names, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m filtered_eu \u001b[39m=\u001b[39m filtered_travel_words[filtered_travel_words\u001b[39m.\u001b[39mswifter\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x[\u001b[39m\"\u001b[39m\u001b[39mcountries\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/swifter/swifter.py:436\u001b[0m, in \u001b[0;36mDataFrameAccessor.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parallel_apply(func, axis, raw, result_type, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# use pandas\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pandas_apply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj, func, axis, raw, result_type, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/swifter/swifter.py:349\u001b[0m, in \u001b[0;36mDataFrameAccessor._pandas_apply\u001b[0;34m(self, df, func, axis, raw, result_type, *args, **kwds)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     apply_func \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m apply_func(func, axis\u001b[39m=\u001b[39;49maxis, raw\u001b[39m=\u001b[39;49mraw, result_type\u001b[39m=\u001b[39;49mresult_type, args\u001b[39m=\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/tqdm/std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    806\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/tqdm/std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    795\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m, in \u001b[0;36midentify_eu_names\u001b[0;34m(row_dataset)\u001b[0m\n\u001b[1;32m     12\u001b[0m country_hits \u001b[39m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i, names_re \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(names_re_list):\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(names_re, name) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(codes_set_list[i]\u001b[39m.\u001b[39mintersection(row_dataset[\u001b[39m\"\u001b[39;49m\u001b[39mname_list\u001b[39;49m\u001b[39m\"\u001b[39;49m])):\n\u001b[1;32m     16\u001b[0m         country_hits\u001b[39m.\u001b[39mappend(country_names[i])\n\u001b[1;32m     18\u001b[0m row_dataset[\u001b[39m\"\u001b[39m\u001b[39mcountries\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m country_hits\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3651\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_loc\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   3626\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m \u001b[39m    Get integer location, slice or boolean mask for requested label.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3649\u001b[0m \u001b[39m    array([False,  True, False,  True])\u001b[39;00m\n\u001b[1;32m   3650\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3651\u001b[0m     casted_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_indexer(key)\n\u001b[1;32m   3652\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   3653\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n",
      "File \u001b[0;32m~/Desktop/xandr/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6354\u001b[0m, in \u001b[0;36mIndex._maybe_cast_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   6350\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEnd slice bound is non-scalar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6352\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mslice\u001b[39m(start_slice, end_slice, step)\n\u001b[0;32m-> 6354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_cast_indexer\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   6355\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6356\u001b[0m \u001b[39m    If we have a float key and are not a floating index, then try to cast\u001b[39;00m\n\u001b[1;32m   6357\u001b[0m \u001b[39m    to an int if equivalent.\u001b[39;00m\n\u001b[1;32m   6358\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   6359\u001b[0m     \u001b[39mreturn\u001b[39;00m key\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def filter_eu_names(row):\n",
    "    # does the full country name occur anywhere or does a countrycode match an item exactly?\n",
    "    return bool(re.search(eu_names_re, row[\"name\"]) or len(eu_codes.intersection(row[\"name_list\"])))\n",
    "\n",
    "\n",
    "names_re_list = eu_countries[\"names_re\"].values\n",
    "codes_set_list = eu_countries[\"codes_set\"].values\n",
    "country_names = eu_countries[\"name\"].values\n",
    "\n",
    "def identify_eu_names(row_dataset):\n",
    "    name = row_dataset[\"name\"]\n",
    "    country_hits = []\n",
    "    for i, names_re in enumerate(names_re_list):\n",
    "         \n",
    "        if re.search(names_re, name) or len(codes_set_list[i].intersection(row_dataset[\"name_list\"])):\n",
    "            country_hits.append(country_names[i])\n",
    "    \n",
    "    row_dataset[\"countries\"] = country_hits\n",
    "    return row_dataset\n",
    "\n",
    "\n",
    "filtered_travel_words = filtered_travel_words.swifter.apply(identify_eu_names, axis=1)\n",
    "filtered_eu = filtered_travel_words[filtered_travel_words.swifter.apply(lambda x: len(x[\"countries\"])>0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856374ceda074bbaa7ab47ccbc22fc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/613906 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_eu = filtered_travel_words[filtered_travel_words.swifter.apply(lambda x: len(x[\"countries\"])>0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_eu.to_csv(\"filtered_eu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86dacdbbf704942b7f5e2a290c754ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/622147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf9585d76a441f8a7a75deb36518b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/622147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def filter_eu_codes(row):\n",
    "    return len(eu_codes.intersection(row[\"name_list\"])) > 0\n",
    "\n",
    "eu_ethnicities_re = utils.list_to_regex([x[1] for x in eu_countries[\"strings\"].values])\n",
    "\n",
    "def filter_eu_ethnicities(row):\n",
    "    return bool(re.search(eu_ethnicities_re, row[\"name\"]))\n",
    "\n",
    "\n",
    "filtered_travel_words[filtered_travel_words.swifter.apply(filter_eu_codes, axis=1)].to_csv(\"filtered_eu_codes.csv\")\n",
    "filtered_travel_words[filtered_travel_words.swifter.apply(filter_eu_ethnicities, axis=1)].to_csv(\"filtered_eu_ethnicities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filtered_eu_segnames.json\", \"w\") as f:\n",
    "    json.dump(list(filtered_eu[\"name\"].array), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = eu_countries[\"name\"].values\n",
    "strings = eu_countries[\"strings\"].values\n",
    "codes = eu_countries[\"codes\"].values\n",
    "identifiers = eu_countries[\"identifiers\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_counter = {country: [] for country in countries}\n",
    "\n",
    "country_re = [utils.list_to_regex(strings[i]+identifiers[i]) for i in range(len(strings))]\n",
    "\n",
    "for index, row_dataset in filtered_travel_words.iterrows():\n",
    "    for i, country in enumerate(countries):\n",
    "        segname = row_dataset[\"name\"]\n",
    "        \n",
    "        if re.search(country_re[i], segname) or codes[i] in row_dataset[\"name_list\"]:\n",
    "            eu_counter[country].append(segname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "germany 4849\n",
      "spain 3528\n",
      "france 3371\n",
      "italy 2288\n",
      "denmark 1953\n",
      "sweden 1398\n",
      "europe 1037\n",
      "poland 544\n",
      "finland 507\n",
      "austria 477\n",
      "belgium 455\n",
      "romania 406\n",
      "netherlands 374\n",
      "hungary 268\n",
      "portugal 211\n",
      "greece 155\n",
      "ireland 117\n",
      "czechia 98\n",
      "croatia 28\n",
      "malta 25\n",
      "bulgaria 18\n",
      "slovakia 18\n",
      "estonia 15\n",
      "cyprus 15\n",
      "slovenia 14\n",
      "lithuania 13\n",
      "latvia 12\n",
      "luxembourg 11\n"
     ]
    }
   ],
   "source": [
    "counts = OrderedDict([(k, len(v)) for k,v in eu_counter.items()])\n",
    "for a, b in sorted(counts.items(), key= lambda x: x[1], reverse=True):\n",
    "    print(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i[1] for i in counts.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
